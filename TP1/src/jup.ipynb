{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Ejercicio 1\n",
    "\n",
    "Gi: guste el programa i, J: es joven, V: es viejo\n",
    "\n",
    "P(J|G1,G3,~G2,~G4) (1)= P(G1,G3,~G2,~G4|J).P(J) / P(G1,G3,~G2,~G4)\n",
    "(2)= P(G1|J).P(G2|J).P(~G3|J).P(~G4|J).P(J) / P(G1).P(G2).P(~G3).P(~G4) = 0.18\n",
    "\n",
    "(1): Teorema de bayes, (2): Asumimos independencia de sucesos\n",
    "\n",
    "P(V|G1,G3,~G2,~G4) = 1 - P(J|G1,G3,~G2,~G4) = 0.82"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Ejercicio 2\n",
    "\n",
    "Importamos el dataset y las librerias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Es de Nacionalidad :E\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from TP1.src.Ej2 import divide_by_nationality\n",
    "from TP1.src.NaiveBayes import NaiveBayes\n",
    "\n",
    "data = pd.read_excel('../PreferenciasBritanicos.xlsx', sheet_name='Hoja1', )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Separamos el dataset en escoceses e ingleses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "britanicos = divide_by_nationality(data, 'I')\n",
    "escocesas = divide_by_nationality(data, 'E')\n",
    "\n",
    "datasets = [britanicos, escocesas]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Instanciamos nuestra implementacion de Naive Bayes y la entrenamos con nuestro dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "nb = NaiveBayes()\n",
    "nb.train(datasets)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Clasificamos la siguiente entrada: [1, 0, 1, 1, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Es de Nacionalidad :E\n"
     ]
    }
   ],
   "source": [
    "category = nb.calculate_category([1, 0, 1, 1, 0])\n",
    "\n",
    "print(\"Es de Nacionalidad :\" + str(datasets[category]['Nacionalidad'].values[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Ejercicio 3\n",
    "\n",
    "Importamos el dataset y librerias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from TP1.src.Ej3 import add_columns_from_text, get_categories, separate_in_categories, confusion_matrix, get_metrics, \\\n",
    "    invert_dict, roc_curve\n",
    "import pandas as pd\n",
    "from TP1.src.NaiveBayes import NaiveBayes\n",
    "\n",
    "df = pd.read_csv('../dataset/Noticias_argentinas.csv', nrows=1000)\n",
    "\n",
    "df = df[['titular', 'categoria']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agregamos una columna por palabra que aparece en algun titual y para cada fila indicamos con 1 si pertenece al titular y con 0 si no pertenece."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "df = add_columns_from_text(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtenemos las 4 categorias que vamos a clasificar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "categories = get_categories(df)[0:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Separamos el dataset en training y test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "train = df.sample(frac=0.8)\n",
    "test = df.drop(train.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Particionamos los dataframes en categorias y luego eliminamos las columnas innecesarias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "train_datasets = separate_in_categories(train, categories)\n",
    "test_datasets = separate_in_categories(test, categories)\n",
    "\n",
    "train_datasets = [df.drop(columns=['titular', 'categoria']) for df in train_datasets]\n",
    "test_datasets = [df.drop(columns=['titular', 'categoria']) for df in test_datasets]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos una instancia de nuestra implementación de Naive Bayes y entrenamos con nuestro dataset de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "nb = NaiveBayes()\n",
    "nb.train(train_datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generamos la matriz de confusión utilizando el dataset de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "res = confusion_matrix(nb, test_datasets)\n",
    "res_dic = {categories[i]: {categories[j]: res[i][j] for j in range(len(res[i]))} for i in range(len(res))}\n",
    "\n",
    "print(pd.DataFrame.from_dict(res_dic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculamos métricas de evaluación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "metrics_dic = get_metrics(res, categories)\n",
    "print(pd.DataFrame.from_dict(invert_dict(metrics_dic)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generamos un espacio ROC para graficar los resultados para cada categoria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "roc_curve(metrics_dic)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (MachineLearning)",
   "language": "python",
   "name": "pycharm-fdf09aa3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}